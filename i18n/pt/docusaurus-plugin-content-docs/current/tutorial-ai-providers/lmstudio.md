---
sidebar_position: 15
---

# LM Studio

Site oficial [https://lmstudio.ai/](https://lmstudio.ai/)

## Conectar LM Studio
- Baixe o LM Studio aqui [lmstudio.ai](https://lmstudio.ai/)
- Abra o LM Studio e navegue até a aba `My Models`. Certifique-se de baixar um modelo.
- Se você não baixou um modelo, vá para a aba `Search` e procure por um modelo.

  <p align="center"><img width="550" height="400" src="https://github.com/user-attachments/assets/1c55f614-9fff-449f-a5df-2a0655d6e7ec"/></p>

- Em seguida, vá para a aba `Local Server`.
- Clique em `Select a model to load` e escolha um modelo.

<p align="center"><img width="550" height="400" src="https://github.com/user-attachments/assets/4286c491-2a27-435f-8aa5-4300733da972"/></p>

- Aguarde até que o carregamento atinja 100% de conclusão.
- Clique em `Start Server` e mantenha o LM Studio em execução.
- Na extensão CodeGPT do VSCode, altere o modelo no chat.

<p align="center"><img width="550" height="400" src="https://github.com/user-attachments/assets/0a6791c5-bdf1-4410-a77a-4e9083993b7a"/></p>

- Selecione `Local LLMs` e escolha `LLM Studio` como `Provider`.
- Use os modelos disponíveis diretamente. Clique fora das opções e peça para conversar.

  <p align="center"><img width="550" height="400" src="https://github.com/user-attachments/assets/3d79427b-efc1-46d7-84ba-21a5870993d4"/></p>

:::caution Remover Chave 
Você não precisa desconectar; pode mudar o provedor. Se o agente não responder e aparecer um "Gain error", feche o VSCode. Em seguida, certifique-se de que o LM Studio esteja em execução com o modelo antes de reabri-lo.
:::