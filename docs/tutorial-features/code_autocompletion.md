---
sidebar_position: 2
---

# Autocomplete

The Autocomplete feature empowers you to choose from a curated selection of models, including those from Mistral and Ollama. This advanced tool enhances your coding experience by providing accurate and contextually relevant code suggestions.

## How to Use:
- Go to Autocomplete on CodeGPT Settings:
    - Check the option âœ… **Autocomplete ON**
    - **Provider:**
        - CodeGPT Plus - Plus
        - Mistral - codestral-latest
        - Ollama - deepseek-coder:base
        - Ollama- codestral:latest
        - Ollama deepseeek-coder:base
        - Ollama codeqwen:code
        - Ollama codellama:code
        - Ollama codegemma:code
        - Ollama starcoder2
        - Ollama - codegpt/deepseek-coder-1.3b-typescript
    - **Max Tokens:** The maximum number of tokens to generate. The model will stop once this many tokens have been generated, so this value trades off between latency and coherence.
    -  **Suggestion Delay:** The delay in **milliseconds** between the last character typed and the request for suggestions. By default is 3000.

:::note Autocomplete settings
<p align="center">
      <img width="400" height="550" src="https://github.com/user-attachments/assets/c67f13b0-09b8-413a-8a55-94264e54bb51" />
</p>

:::

- Effortless Integration: Seamlessly incorporate the suggested code snippets into your project, improving code quality and efficiency. Press `Tab` to accept the suggestion

:::note Autocomplete
<p align="center">
      <img width="750" height="550" src="https://github.com/user-attachments/assets/f91bce5a-9495-4e0d-a366-5998e804d3cb" />
</p>

:::
